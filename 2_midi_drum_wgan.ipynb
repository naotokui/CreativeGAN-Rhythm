{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN for MIDI Rhythm Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess midi data with `0_preprocess_midi.ipynb` in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # only relevant to my own environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRUM_CLASSES = [\n",
    "   'Kick',\n",
    "   'Snare',\n",
    "   'Hi-hat closed',\n",
    "   'Hi-hat open',\n",
    "   'Tom low',\n",
    "   'Tom mid', \n",
    "   'Tom high',\n",
    "   'Clap',\n",
    "   'Rim' \n",
    "]\n",
    "MIDI_DRUM_MAP = {\n",
    "   36: 0,\n",
    "   35: 0,\n",
    "   38: 1,\n",
    "   27: 1,\n",
    "   28: 1,\n",
    "   31: 1,\n",
    "   32: 1,\n",
    "   33: 1,\n",
    "   34: 1,\n",
    "   37: 1,\n",
    "   39: 1,\n",
    "   40: 1,\n",
    "   56: 1,\n",
    "   65: 1,\n",
    "   66: 1,\n",
    "   75: 1,\n",
    "   85: 1,\n",
    "   42: 2,\n",
    "   44: 2,\n",
    "   54: 2,\n",
    "   68: 2,\n",
    "   69: 2,\n",
    "   70: 2,\n",
    "   71: 2,\n",
    "   73: 2,\n",
    "   78: 2,\n",
    "   80: 2,\n",
    "   46: 3,\n",
    "   67: 3,\n",
    "   72: 3,\n",
    "   74: 3,\n",
    "   79: 3,\n",
    "   81: 3,\n",
    "   45: 4,\n",
    "   29: 4,\n",
    "   41: 4,\n",
    "   61: 4,\n",
    "   64: 4,\n",
    "   84: 4,\n",
    "   48: 5,\n",
    "   47: 5,\n",
    "   60: 5,\n",
    "   63: 5,\n",
    "   77: 5,\n",
    "   86: 5,\n",
    "   87: 5,\n",
    "   50: 6,\n",
    "   30: 6,\n",
    "   43: 6,\n",
    "   62: 6,\n",
    "   76: 6,\n",
    "   83: 6,\n",
    "   49: 7,\n",
    "   55: 7,\n",
    "   57: 7,\n",
    "   58: 7,\n",
    "   51: 8,\n",
    "   52: 8,\n",
    "   53: 8,\n",
    "   59: 8,\n",
    "   82: 8\n",
    "}\n",
    "\n",
    "DRUM_MIDI_MAP = [ # pianoroll to MIDI - reverse\n",
    "    36, # 0 Kick\n",
    "    38, # 1 Snare\n",
    "    42, # 2 Hihat Closed\n",
    "    46, # 3 Hihat Open\n",
    "    45, # 4 Tom Low\n",
    "    47, # 5 Tom Mid\n",
    "    50, # 6 Tom High\n",
    "    49, # 7 Clap\n",
    "    51  # 8 Rim\n",
    "]\n",
    "\n",
    "resolution  = 4 # separate quater into 4  = 16 notes per bar\n",
    "\n",
    "nb_bars = 2 \n",
    "\n",
    "len_seq = resolution * 4 * nb_bars # length of drumloops in training data - 2 bars\n",
    "    \n",
    "nb_notes = len(DRUM_CLASSES) # number of possible MIDI notes  - max_drum_note - min_drum_note\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# # load pianoroll matrix - see \"0_preprocess_midi.ipynb\"\n",
    "\n",
    "# matrices_drums = np.load(\"./tmp/matrices_drum_gm_electronic.npz\")['drum_data']\n",
    "# matrices_genres = np.load(\"./tmp/matrices_drum_gm_electronic.npz\")['genre_ids']\n",
    "# GENRES_ALL = np.load(\"./tmp/matrices_drum_gm_electronic.npz\")['genres']\n",
    "\n",
    "# print(GENRES_ALL)\n",
    "# print(matrices_genres.shape)\n",
    "\n",
    "# # Filter genres \n",
    "# GENRES_USED = [u'Old Skool', u'DnB', u'Jungle', u'House', u'Breakbeat', u'Garage', u'Techno']\n",
    "# GENRES_ID_USED = [i for i, genre in enumerate(GENRES_ALL) if genre in GENRES_USED]\n",
    "# GENRES = [genre for i, genre in enumerate(GENRES_ALL) if genre in GENRES_USED]\n",
    "# NB_GENRES = len(GENRES)\n",
    "\n",
    "# print(GENRES_ID_USED)\n",
    "# print(NB_GENRES, GENRES)\n",
    "\n",
    "# _drums = []\n",
    "# _genres = []\n",
    "\n",
    "# for genre_id, drum in zip(matrices_genres, matrices_drums):\n",
    "#     if genre_id in GENRES_ID_USED:\n",
    "#         _drums.append(drum)\n",
    "#         genre_id = GENRES_ID_USED.index(genre_id)\n",
    "#         _genres.append(genre_id)\n",
    "\n",
    "# matrices_drums = np.array(_drums)\n",
    "# print(matrices_drums.shape)\n",
    "# matrices_genres = np.array(_genres)\n",
    "# print(matrices_genres.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['latin' 'jazz' 'soul' 'hiphop' 'rock' 'funk']\n",
      "(16657,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# make sure you have run \"0_preprocess_midi.ipynb\" in advance\n",
    "matrices_drums = np.load(\"./tmp/matrices_drum_groove_genres.npz\")['onsets']\n",
    "matrices_velocities = np.load(\"./tmp/matrices_drum_groove_genres.npz\")['velocities']\n",
    "matrices_offsets = np.load(\"./tmp/matrices_drum_groove_genres.npz\")['timeshifts']\n",
    "matrices_genres = np.load(\"./tmp/matrices_drum_groove_genres.npz\")['genre_ids']\n",
    "GENRES = np.load(\"./tmp/matrices_drum_groove_genres.npz\")['genres']\n",
    "\n",
    "NB_GENRES = len(GENRES)\n",
    "print(GENRES)\n",
    "print(matrices_genres.shape)\n",
    "\n",
    "# # Filter genres \n",
    "# GENRES_USED = [u'Old Skool', u'DnB', u'Jungle', u'House', u'Breakbeat', u'Garage', u'Techno']\n",
    "# GENRES_ID_USED = [i for i, genre in enumerate(GENRES_ALL) if genre in GENRES_USED]\n",
    "# GENRES = [genre for i, genre in enumerate(GENRES_ALL) if genre in GENRES_USED]\n",
    "# NB_GENRES = len(GENRES)\n",
    "\n",
    "# print(GENRES_ID_USED)\n",
    "# print(NB_GENRES, GENRES)\n",
    "\n",
    "# _drums = []\n",
    "# _genres = []\n",
    "\n",
    "# for genre_id, drum in zip(matrices_genres, matrices_drums):\n",
    "#     if genre_id in GENRES_ID_USED:\n",
    "#         _drums.append(drum)\n",
    "#         genre_id = GENRES_ID_USED.index(genre_id)\n",
    "#         _genres.append(genre_id)\n",
    "\n",
    "# matrices_drums = np.array(_drums)\n",
    "# print(matrices_drums.shape)\n",
    "# matrices_genres = np.array(_genres)\n",
    "# print(matrices_genres.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return -K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1129 12:59:46.060204 140215157856000 deprecation_wrapper.py:119] From /home/nao/anaconda3/envs/p2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1129 12:59:46.069303 140215157856000 deprecation_wrapper.py:119] From /home/nao/anaconda3/envs/p2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1129 12:59:46.071274 140215157856000 deprecation_wrapper.py:119] From /home/nao/anaconda3/envs/p2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1129 12:59:46.168083 140215157856000 deprecation_wrapper.py:119] From /home/nao/anaconda3/envs/p2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1129 12:59:46.173268 140215157856000 deprecation.py:506] From /home/nao/anaconda3/envs/p2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1129 12:59:46.911823 140215157856000 deprecation_wrapper.py:119] From /home/nao/anaconda3/envs/p2/lib/python2.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "drum_input (InputLayer)      (None, 32, 9)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 32, 256)           141312    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 32, 256)           394240    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 4,730,881\n",
      "Trainable params: 4,730,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Reshape, LSTM, Bidirectional\n",
    "from keras.layers import Embedding, Concatenate\n",
    "from keras.layers.convolutional import Conv2D\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "\n",
    "# # encoder\n",
    "# drum_input = Input(shape=(len_seq, nb_notes), name='drum_input')  # tensorflow order\n",
    "\n",
    "# x = Bidirectional(LSTM(64, return_sequences=True, activation='tanh'))(drum_input) \n",
    "# x = Bidirectional(LSTM(64, return_sequences=False, activation='tanh'))(x)\n",
    "# x = Dense(256)(x)\n",
    "# x = LeakyReLU(alpha=0.01)(x)\n",
    "# output = Dense(1)(x)\n",
    "\n",
    "# discriminator = Model(drum_input, output)\n",
    "# discriminator.summary()\n",
    "\n",
    "# optimizer = RMSprop ( lr = 0.0008 )  # higher leraning rate for D\n",
    "# discriminator.compile(optimizer=optimizer, loss='binary_crossentropy', \n",
    "#                       metrics=['accuracy'])\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Reshape, LSTM\n",
    "from keras.layers import Bidirectional, Lambda, Concatenate, Softmax, BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "droprate = 0.4\n",
    "\n",
    "# input\n",
    "drum_input = Input(shape=(len_seq, nb_notes), name='drum_input')  # tensorflow order\n",
    "# offset_input = Input(shape=(len_seq, nb_notes), name='offset_input')  # tensorflow order\n",
    "\n",
    "x0 = Bidirectional(LSTM(128, return_sequences=True, activation='tanh', dropout=droprate, recurrent_dropout=droprate))(drum_input) \n",
    "#x0 = BatchNormalization()(x0)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True, activation='tanh', dropout=droprate, recurrent_dropout=droprate))(x0)\n",
    "#x0 = BatchNormalization()(x0)\n",
    "#x0 = Dropout(droprate)(x0)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "# x1 = Bidirectional(LSTM(128, return_sequences=True, activation='tanh', dropout=droprate, recurrent_dropout=droprate))(offset_input) \n",
    "# x1 = BatchNormalization()(x1)\n",
    "# x1 = Bidirectional(LSTM(128, return_sequences=False, activation='tanh', dropout=droprate, recurrent_dropout=droprate))(x1)\n",
    "# x1 = BatchNormalization()(x1)\n",
    "# #x1 = Dropout(droprate)(x1)\n",
    "\n",
    "# x = Concatenate(axis=-1)([x0, x1])\n",
    "#x = Dropout(droprate)(x0)\n",
    "#x = LeakyReLU(alpha=0.01)(x)\n",
    "x = Dense(512, activation='sigmoid')(x)\n",
    "output = Dense(1, activation=None)(x)\n",
    "#output = LeakyReLU(alpha=0.01)(x)\n",
    "\n",
    "discriminator = Model(drum_input, output)\n",
    "discriminator.summary()\n",
    "\n",
    "optimizer = RMSprop ( lr = 0.00005 )  # higher leraning rate for D\n",
    "discriminator.compile(optimizer=optimizer, loss=wasserstein_loss, \n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATOR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 32, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32, 512)           1116160   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 32, 9)             18792     \n",
      "=================================================================\n",
      "Total params: 3,497,320\n",
      "Trainable params: 3,497,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Reshape, Conv2DTranspose, RepeatVector, Activation,Bidirectional,multiply\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "\n",
    "len_input = 256\n",
    "\n",
    "z_input = Input(shape=(len_input,))  # tensorflow order\n",
    "\n",
    "# x = Dense(512)(z_input)\n",
    "# x = LeakyReLU(alpha=0.2)(x)\n",
    "# x = BatchNormalization(momentum=0.9)(x)\n",
    "x = Dense(1024)(z_input)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "#x = BatchNormalization(momentum=0.9)(x)\n",
    "x = Reshape((32, 32))(x)\n",
    "\n",
    "x = LSTM(512, return_sequences=True, activation='tanh')(x) \n",
    "x = LSTM(512, return_sequences=True, activation='tanh')(x)\n",
    "note_out = LSTM(9, return_sequences=True, activation='sigmoid')(x)\n",
    "# output = LeakyReLU()(x)\n",
    "\n",
    "generator = Model(z_input, note_out)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADVERSARIAL MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 32, 9)             3497320   \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1)                 4730881   \n",
      "=================================================================\n",
      "Total params: 8,228,201\n",
      "Trainable params: 3,497,320\n",
      "Non-trainable params: 4,730,881\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "# define input for the combined GAN model\n",
    "z_input = Input(shape=(len_input,))  # tensorflow order\n",
    "img_gan = generator(z_input)\n",
    "\n",
    "# training is disable for discriminator in adversarial model\n",
    "discriminator.trainable = False \n",
    "\n",
    "# define output\n",
    "prediction_gan = discriminator(img_gan)\n",
    "\n",
    "# define combined GAN model\n",
    "gan = Model(z_input, prediction_gan)\n",
    "\n",
    "optimizer = RMSprop ( lr = 0.00005 )\n",
    "gan.compile(optimizer=optimizer, loss=wasserstein_loss, metrics=['accuracy'])\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "['loss', 'acc']\n"
     ]
    }
   ],
   "source": [
    "print(gan.metrics_names)\n",
    "print (discriminator.metrics_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import pretty_midi\n",
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Create Z for generator\n",
    "def get_noise(batch_size, len_input):\n",
    "#    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, len_input])\n",
    "    \n",
    "    # better to use a spherical Z. according to https://github.com/soumith/ganhacks\n",
    "    noise = np.random.normal(0.0, 1.0, size=[batch_size, len_input])\n",
    "    return noise\n",
    "\n",
    "def plot_drum_matrix(a):\n",
    "    if a is not None:\n",
    "        a = np.transpose(np.squeeze(a))\n",
    "        plt.matshow(a)\n",
    "        plt.show()  \n",
    "        \n",
    "        import pretty_midi\n",
    "\n",
    "def play_drum_matrix(mat, tempo=120.0):\n",
    "    # generate audio\n",
    "    audio_data = get_audio_from_drum_matrix(mat, tempo=tempo)\n",
    "    display(Audio(audio_data, rate=44100))\n",
    "    return audio_data\n",
    "\n",
    "def get_audio_from_drum_matrix(mat, tempo=120.):\n",
    "    pm = pretty_midi.PrettyMIDI(initial_tempo=tempo) # midi object\n",
    "    pm_inst = pretty_midi.Instrument(0, is_drum=True) # midi instrument\n",
    "    \n",
    "    timestep = (60./tempo) / 4. # duration of a 16th note\n",
    "    for position, timeslot in enumerate(mat):\n",
    "        for inst, onset in enumerate(timeslot):\n",
    "            if onset > 0.:\n",
    "                note_number = DRUM_MIDI_MAP[inst]\n",
    "                velocity = int(onset * 127.)\n",
    "                start = timestep * position\n",
    "                end = timestep * (position + 0.5)\n",
    "                \n",
    "                # create a midi note\n",
    "                note = pretty_midi.Note(velocity=velocity, pitch=note_number, start=start, end=end)\n",
    "                pm_inst.notes.append(note)\n",
    "    pm.instruments.append(pm_inst)\n",
    "\n",
    "    # midi -> audio\n",
    "    audio_data = pm.fluidsynth()\n",
    "    return audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir=/tmp/tf_logs_gan/\n"
     ]
    }
   ],
   "source": [
    "from tensorboard_logger import configure, log_value\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "logdir_prefix = \"/tmp/tf_logs_gan/\"\n",
    "logdir = logdir_prefix + now.strftime(\"%Y%m%d-%H%M%S\") \n",
    "cmd = \"tensorboard --logdir=\" + logdir_prefix\n",
    "print (cmd)\n",
    "\n",
    "configure(logdir, flush_secs=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "\n",
    "batch_size = 64\n",
    "nb_epochs = 300\n",
    "nb_samples = matrices_drums.shape[0]\n",
    "\n",
    "D_unrolled = 5\n",
    "G_unrolled = 1\n",
    "MAX_LOSS_RATIO = 3.0\n",
    "\n",
    "clip_threshold = 0.01\n",
    "\n",
    "# Labels for real images: all onesã€€# label 0: fake 1: real\n",
    "real_labels = np.ones((batch_size, 1)) # * 0.9 # one-sided soft labeling\n",
    "\n",
    "# Labels for fake images: all -1s\n",
    "fake_labels = np.ones((batch_size, 1))*-1\n",
    "\n",
    "train_d = True\n",
    "train_g = True\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    \n",
    "    nb_steps = int(nb_samples/batch_size)\n",
    "    for repeat in range(nb_steps):\n",
    "        \n",
    "        step = nb_steps * epoch + repeat\n",
    "        \n",
    "        # Training D\n",
    "        if train_d:\n",
    "            \n",
    "            m_d_loss = 0.0\n",
    "            m_d_accuracy = 0.0\n",
    "            \n",
    "            for j in range(D_unrolled):\n",
    "                # training data\n",
    "                random_indices = np.random.randint(0, matrices_drums.shape[0], size=batch_size)\n",
    "                drum_train = matrices_drums[random_indices, :, :]\n",
    "                \n",
    "                # generated samples\n",
    "                noise = get_noise(batch_size, len_input)\n",
    "                drum_fake = generator.predict(noise)\n",
    "\n",
    "                # training D\n",
    "                d_loss_real = discriminator.train_on_batch(drum_train, real_labels)\n",
    "                d_loss_fake = discriminator.train_on_batch(drum_fake, fake_labels)      \n",
    "                d_loss, d_accuracy = 0.5 * np.add(d_loss_real, d_loss_fake) # average\n",
    "\n",
    "                m_d_loss += d_loss\n",
    "                m_d_accuracy += d_accuracy\n",
    "\n",
    "                # clip weights for WGAN\n",
    "                for l in discriminator.layers:\n",
    "                    weights = l.get_weights()\n",
    "                    weights = [np.clip(w, -clip_threshold, clip_threshold) for w in weights]\n",
    "                    l.set_weights(weights)\n",
    "                \n",
    "                # cache for later update\n",
    "    #             cache_weights = discriminator.get_weights()\n",
    "          \n",
    "            m_d_loss /= float(D_unrolled)\n",
    "            m_d_accuracy /= float(D_unrolled)\n",
    "            \n",
    "        # store value\n",
    "        log_value(\"D loss\", m_d_loss, step)  \n",
    "        log_value(\"D accuracy\", m_d_accuracy, step)  \n",
    "        \n",
    "        # Training G\n",
    "        if train_g:\n",
    "            y = np.ones([batch_size, 1]) # watch out the label! it should be one here         \n",
    "            m_a_loss = 0.0\n",
    "            m_a_accuracy = 0.0  \n",
    "            \n",
    "            for j in range(G_unrolled): \n",
    "                noise = get_noise(batch_size, len_input)\n",
    "                a_loss, a_acc = gan.train_on_batch(noise, y)\n",
    "                m_a_loss += a_loss\n",
    "                m_a_accuracy += a_acc\n",
    "                \n",
    "            m_a_loss /= float(G_unrolled)\n",
    "            m_a_accuracy /= float(G_unrolled)\n",
    "                \n",
    "        # store value\n",
    "        log_value(\"adversarial loss\", m_a_loss, step)\n",
    "        log_value(\"G accuracy\", m_a_accuracy, step)\n",
    "                    \n",
    "#         if train_d and train_g:\n",
    "#             if m_a_loss / m_d_loss > MAX_LOSS_RATIO:\n",
    "#                 train_d = False\n",
    "#                 print (\"Pausing D\")\n",
    "#             elif m_d_loss / m_a_loss > MAX_LOSS_RATIO:\n",
    "#                 train_g = False\n",
    "#                 print (\"Pausing G\")\n",
    "#         else:\n",
    "#             train_d = True\n",
    "#             train_g = True\n",
    "            \n",
    "        # update layer \n",
    "#         discriminator.set_weights(cache_weights)\n",
    "    \n",
    "        if repeat % 100 == 0:            \n",
    "            print(\"epoch\", epoch, repeat)\n",
    "            print(\"d_loss\", m_d_loss, \"a_loss\", a_loss) # print mean loss)\n",
    "            print(\"d_accuracy\", m_d_accuracy )\n",
    "                        \n",
    "            # sample output\n",
    "            noise = get_noise(1, len_input)\n",
    "            drum_generated = generator.predict(noise)            \n",
    "            plot_drum_matrix(drum_generated)\n",
    "            \n",
    "            # sample audio output\n",
    "            audio_data = play_drum_matrix(np.squeeze(drum_generated))\n",
    "            wavfile.write(\"audio/groove_drum_%05d_%05d.wav\" % (epoch, repeat), 44100, audio_data)\n",
    "            \n",
    "            print\n",
    "            print\n",
    "            \n",
    "                        \n",
    "    # store temporary models\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        generator.save(\"./tmp/generator-epoch-%03d-%0.5f.h5\" % (epoch, a_loss))\n",
    "        gan.save(\"./tmp/gan-epoch-%03d-%0.5f.h5\" % (epoch, a_loss))\n",
    "        discriminator.save(\"./tmp/discriminator-epoch-%03d-%0.5f.h5\" % (epoch, m_d_loss))\n",
    "        clear_output(wait=True) # clear here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1024x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1024x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1024x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    noise = get_noise(1, len_input)\n",
    "    drum_generated = generator.predict(noise)\n",
    "    plot_drum_matrix(drum_generated)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
